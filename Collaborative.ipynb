{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import StructType,StructField,IntegerType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants : Modify as and when required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "business_file=\"Sample_Datasets/montreal_business/part-00000-b5f251d0-79e6-47a8-a405-042eb7b7894e-c000.snappy.parquet\"\n",
    "reviews_file=\"Sample_Datasets/montreal_reviews/part-00000-f0e4463e-0ac9-402e-b995-734cbefc958e-c000.snappy.parquet\"\n",
    "users_file=\"Sample_Datasets/montreal_users/part-00000-a7d49d78-89a7-478f-a577-0efe02dca047-c000.snappy.parquet\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "app_name=\"Collaborative filtering for restaurant recommendation\"\n",
    "\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(app_name) \\\n",
    "        .getOrCreate()\n",
    "    return spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset in Apache Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=init_spark()\n",
    "business_df = spark.read.parquet(business_file)\n",
    "reviews_df=spark.read.parquet(reviews_file)\n",
    "users_df=spark.read.parquet(users_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting required features\n",
    "\n",
    "In our project, we are only concerned with a subset of columns from the dataset, specifically those that are relevant to our goal of recommending restaurants in Montreal. Therefore, we extract the necessary features from the business_df table, including the id, name, stars, category. \n",
    "Similarly, we filter the reviews_df table to include only reviews for the selected restaurants by performing an inner join with business_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df = business_df.select(\"business_id\",\"name\", \"stars\", \n",
    "                                 \"review_count\", \"address\", \"city\", \"state\", \"postal_code\", \"longitude\", \n",
    "                                 \"categories\", \"latitude\").withColumnRenamed(\"stars\", \"stars_restaurant\")\n",
    "reviews_df = reviews_df.join(business_df, on='business_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for ALS: Convert String to index\n",
    "Prior to initiating the modeling process, it is essential to transform all the relevant columns to integer type for compatibility with the ALS model from pyspark. The columns requiring conversion are the business_id and user_id. We accomplish this by leveraging the StringIndexer function, which we imported from pyspark.ml.feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[business_id: string, user_id: string, business_id_index: double, user_id_index: double, stars: double, categories: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in ['business_id', 'user_id']]\n",
    "pipeline = Pipeline(stages=indexer)\n",
    "transformed = pipeline.fit(reviews_df).transform(reviews_df)\n",
    "transformed.select(['business_id', 'user_id','business_id_index', 'user_id_index','stars','categories'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the dataset into training and testing subsets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting a seed value as 3 to make randomsplit output deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = transformed.randomSplit([0.8, 0.2],3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ALS model\n",
    "The Apache Spark library provides various parameters for the ALS (Alternating Least Squares) algorithm, including:\n",
    "\n",
    "- rank: the number of latent factors used in the model (default value: 10).\n",
    "- maxIter: the maximum number of iterations to run (default value: 10).\n",
    "- regParam: the regularization parameter used in ALS (default value: 1.0).\n",
    "- implicitPrefs: a boolean value that indicates whether to use the explicit feedback ALS variant or the one adapted for implicit feedback data (default value: false, which means using explicit feedback).\n",
    "- alpha: a parameter that applies to the implicit feedback variant of ALS, determining the baseline confidence in preference observations (default value: 1.0).\n",
    "- nonnegative: a boolean value that specifies whether to use nonnegative constraints for least squares (default value: false)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "als=ALS(maxIter=5,\n",
    "        regParam=0.09,\n",
    "        rank=20,\n",
    "        userCol=\"user_id_index\",\n",
    "        itemCol=\"business_id_index\",\n",
    "        ratingCol=\"stars\",\n",
    "        coldStartStrategy=\"drop\",\n",
    "        nonnegative=True)\n",
    "\n",
    "model=als.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=1.4344524168573067\n"
     ]
    }
   ],
   "source": [
    "evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"stars\",predictionCol=\"prediction\")\n",
    "predictions=model.transform(test)\n",
    "rmse=evaluator.evaluate(predictions)\n",
    "print(\"RMSE=\"+str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=1.3256622625564687\n",
      "42263\n",
      "4169\n",
      "RMSE=1.3197219683901034\n",
      "42263\n",
      "4169\n",
      "RMSE=1.3139086154158246\n",
      "42263\n",
      "4169\n",
      "RMSE=1.284438624757947\n",
      "42263\n",
      "4169\n",
      "RMSE=1.2623386478171916\n",
      "42263\n",
      "4169\n",
      "RMSE=1.2474116071619326\n",
      "42263\n",
      "4169\n",
      "RMSE=1.238762445624405\n",
      "42263\n",
      "4169\n",
      "RMSE=1.2356426249395458\n",
      "42263\n",
      "4169\n",
      "RMSE=1.2395899586518075\n",
      "42263\n",
      "4169\n",
      "RMSE=1.2469344735450594\n",
      "42263\n",
      "4169\n",
      "RMSE=1.2469344735450616\n",
      "42263\n",
      "4169\n",
      "RMSE=1.2721805658805418\n",
      "42263\n",
      "4169\n",
      "RMSE=1.3102064196211636\n",
      "42263\n",
      "4169\n",
      "RMSE=1.3574268518445995\n",
      "42263\n",
      "4169\n",
      "RMSE=1.4111391176146966\n",
      "42263\n",
      "4169\n"
     ]
    }
   ],
   "source": [
    "values=[0.08,0.09,0.1,0.15,0.2,0.25,0.3,0.4,0.45,0.5,0.5,0.6,0.7,0.8,0.9]\n",
    "for rm in values:\n",
    "    als = ALS(maxIter=20,regParam=rm,rank=25,userCol=\"user_id_index\",itemCol=\"business_id_index\",ratingCol=\"stars\",coldStartStrategy=\"drop\",nonnegative=True)\n",
    "    model = als.fit(training)\n",
    "    evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"stars\",predictionCol=\"prediction\")\n",
    "    predictions=model.transform(test)\n",
    "    rmse=evaluator.evaluate(predictions)\n",
    "    print(\"RMSE=\"+str(rmse))\n",
    "    print(model.userFactors.count())\n",
    "    print(model.itemFactors.count())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are uisng 0.4 as the regularizatin parameter as it yields lowest RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE=1.2356426249395458\n",
      "Given ratings vs Predicted ratings\n",
      "+--------------------+--------------------+-----+----------+\n",
      "|             user_id|         business_id|stars|prediction|\n",
      "+--------------------+--------------------+-----+----------+\n",
      "|bIDIIDbZUo1p5Vl8w...|0JGMKaKJGVuDus5Wc...|  5.0|  4.263014|\n",
      "|6KHdW3MjBZJZ4BkzJ...|0W4lkclzZThpx3V65...|  4.0| 3.7163045|\n",
      "|75Xtdm65_xnFXbL3v...|0W4lkclzZThpx3V65...|  5.0| 4.3275266|\n",
      "|C7o1LcGjQis0ICvsQ...|0W4lkclzZThpx3V65...|  4.0| 3.5761085|\n",
      "|w01hd3eejoOkE6kQ9...|17jcc6RYsSgf3NgWE...|  5.0|  4.356521|\n",
      "|yX0g0cSodyqpIzfa6...|1iKMxBsTsPSoEzYUf...|  5.0| 2.3909633|\n",
      "|2av488ePvb-Z4qgeN...|25m6rM6hFw2CGADUj...|  4.0| 3.7119172|\n",
      "|XZeFJAOFwmkw9rCeu...|2gUbgbdJ7IFSbicBX...|  4.0| 4.1132197|\n",
      "|1IpC-cW9MxaM9Tvhj...|2wFSVah7gU9ImNuBH...|  5.0| 4.3055344|\n",
      "|XP9aSaVhu_q1OCUtu...|3DGtOhtb6jNdRs9T9...|  4.0|  3.911713|\n",
      "|lh_0BHrCSx87geLzQ...|3jKUbhGSjFTv5jZ0w...|  5.0|  4.284819|\n",
      "|mJ6yNAm5x5-lyW7mk...|3p0yosq4IE5E2B91P...|  5.0| 3.2425134|\n",
      "|2av488ePvb-Z4qgeN...|46Ld9Qc9nAx_A0jwc...|  4.0| 3.6758802|\n",
      "|Wj_d_8NMCZjv13Z0k...|5PM5THfRcUcljcKRW...|  4.0|  2.301336|\n",
      "|W3o61WWDdvFXc0LUR...|5T6kFKFycym_GkhgO...|  4.0| 4.1153626|\n",
      "|mJ6yNAm5x5-lyW7mk...|6BL92dndWIhhyA7KZ...|  3.0| 3.0736108|\n",
      "|oOfu-75wAzAoAPKzm...|6WDaq9fe39J1THiWI...|  4.0| 2.7489507|\n",
      "|2av488ePvb-Z4qgeN...|6j7kmNdr0aods0C45...|  4.0| 3.1698108|\n",
      "|APqCAC4UX_stiTue-...|7mV10OWvWZlvQahmo...|  4.0| 3.4518971|\n",
      "|RmxuIIpYDy0AI_Mch...|7wgKazvblPECOzBrd...|  2.0|  2.298206|\n",
      "+--------------------+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "als = ALS(maxIter=20,regParam=0.4,rank=25,userCol=\"user_id_index\",itemCol=\"business_id_index\",ratingCol=\"stars\",coldStartStrategy=\"drop\",nonnegative=True)\n",
    "model = als.fit(training)\n",
    "evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"stars\",predictionCol=\"prediction\")\n",
    "predictions=model.transform(test)\n",
    "rmse=evaluator.evaluate(predictions)\n",
    "print(\"RMSE=\"+str(rmse))\n",
    "\n",
    "print(\"Given ratings vs Predicted ratings\")\n",
    "predictions.select(['user_id', 'business_id', 'stars', 'prediction']).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Best Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations():\n",
    "    \"\"\"\n",
    "    Returns top recommendations for a user.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    :py:class:`pyspark.sql.DataFrame`\n",
    "    a DataFrame of (itemCol, recommendations), where recommendations are\n",
    "    stored as an array of ('name','business_id', 'stars', 'categories') Rows.\n",
    "    \"\"\"\n",
    "    test = model.recommendForAllUsers(10).filter(col('user_id_index')==30).select(\"recommendations\").take(10)\n",
    "    topRestaurants = []\n",
    "    for item in test[0][0]:        \n",
    "        topRestaurants.append(item.business_id_index)\n",
    "    \n",
    "    schema = StructType([StructField(\"business_id_index\",IntegerType(),True)])\n",
    "    restaurants = spark.createDataFrame(topRestaurants,IntegerType()).toDF(\"business_id_index\")\n",
    "    return restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_transformed_list():\n",
    "    transformed\\\n",
    "    .select(['name', 'user_id', 'stars', 'categories'])\\\n",
    "    .filter(col('user_id_index')==30)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_top10_recommendations(restaurants):\n",
    "    \"\"\"\n",
    "    Displays the top 10 restaurant recommendations.\n",
    "    \"\"\"\n",
    "    restaurants\\\n",
    "    .join(transformed, on = 'business_id_index', how = 'inner')\\\n",
    "    .select([ 'name','business_id', 'stars', 'categories'])\\\n",
    "    .drop_duplicates(subset=['name'])\\\n",
    "    .show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the Top Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----+--------------------+\n",
      "|               name|         business_id|stars|          categories|\n",
      "+-------------------+--------------------+-----+--------------------+\n",
      "|               180g|OpMGaD7tsUZzt19mf...|  5.0|Books, Mags, Musi...|\n",
      "|        Café Nomade|b--VluQ4oOo9Zqlaz...|  5.0|Restaurants, Food...|\n",
      "|           Dispensa|HwxlCM7TY73C1kcQK...|  5.0|Food, Restaurants...|\n",
      "|  Il Miglio Express|L_ikuudEVAgQNKMcr...|  5.0|Italian, Restaura...|\n",
      "|La Fromagerie Hamel|IxthHWpZgpdt72uOU...|  5.0|Cheese Shops, Res...|\n",
      "|         Melchorita|pRvq-3aYrzzbgEuOw...|  5.0|Latin American, P...|\n",
      "|            Mercado|Y1tXlYIwg26AdewIl...|  5.0|Latin American, B...|\n",
      "|            Parasol|ZwWiPJYA-hk6jtBo9...|  5.0|Wine Bars, Restau...|\n",
      "|            Salerno|n_LSGXDDApdFS9EC2...|  5.0|Restaurants, Pizz...|\n",
      "|         Sushi Shop|79cDBLMfxp_PLMret...|  4.0|Restaurants, Sush...|\n",
      "+-------------------+--------------------+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "top10_recommendations = get_recommendations()\n",
    "display_top10_recommendations(top10_recommendations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
